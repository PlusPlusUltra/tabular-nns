{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9936bc9-7214-49e1-8f0e-c5c68260373e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All CSV files created: task5.csv, task6.csv, task7.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# ---- CONFIGURATION ----\n",
    "datasets_task5 = [\"cmc\", \"connect-4\", \"electricity\", \"eye\", \"kc1\", \"phoneme\", \"pol\", \"splice\", \"vehicle\"]\n",
    "datasets_task6and7 = [\"Diamonds\", \"2dplanes\", \"1000-Cameras-Dataset\", \"Abalone_reg\",\n",
    "                      \"Brazillian_houses_reproduced\", \"Data_science_Salaries\"]\n",
    "techniques = [\"IsolationForest\", \"LocalOutlierFactor\", \"OneClassSVM\", \"ZScore\", \"ModifiedZScore\", \"IQR\"]\n",
    "results_file = \"results.txt\"\n",
    "results_with_outliers_file = \"results_with_outliers.txt\"\n",
    "outlier_log_folder = \"outlier_logs\"\n",
    "\n",
    "# ---- HELPERS ----\n",
    "\n",
    "def parse_results_file(filepath, with_outliers=False):\n",
    "    data = {}\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(',')\n",
    "            if with_outliers:\n",
    "                if len(parts) != 4 or parts[3] == \"ERROR\":\n",
    "                    continue\n",
    "                dataset, model, technique, acc = parts\n",
    "            else:\n",
    "                if len(parts) != 3 or parts[2] == \"ERROR\":\n",
    "                    continue\n",
    "                dataset, model, acc = parts\n",
    "            try:\n",
    "                acc = float(acc)\n",
    "            except ValueError:\n",
    "                continue\n",
    "            if with_outliers:\n",
    "                data.setdefault(dataset, {}).setdefault(model, {})[technique] = acc\n",
    "            else:\n",
    "                data.setdefault(dataset, {})[model] = acc\n",
    "    return data\n",
    "\n",
    "def parse_outlier_log(filepath):\n",
    "    results = {}\n",
    "    with open(filepath, 'r') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    pattern = r\"(.*?) - (train|val|test) \\((.*?)\\):\\s+Outliers detected: (\\d+)\\s+Total samples:\\s+(\\d+)\"\n",
    "    for match in re.finditer(pattern, content):\n",
    "        dataset_full, split, technique, outliers, total = match.groups()\n",
    "        outliers = int(outliers)\n",
    "        total = int(total)\n",
    "        results.setdefault(technique, []).append((outliers, total))\n",
    "\n",
    "    # Aggregate across splits\n",
    "    outlier_perc = {}\n",
    "    for technique, values in results.items():\n",
    "        total_outliers = sum(x[0] for x in values)\n",
    "        total_samples = sum(x[1] for x in values)\n",
    "        perc = total_outliers / total_samples if total_samples > 0 else 0\n",
    "        outlier_perc[technique] = perc\n",
    "    return outlier_perc\n",
    "\n",
    "def get_outlier_data(dataset):\n",
    "    file_path = os.path.join(outlier_log_folder, f\"{dataset}_outliers.txt\")\n",
    "    if not os.path.exists(file_path):\n",
    "        return {}\n",
    "    return parse_outlier_log(file_path)\n",
    "\n",
    "# ---- LOAD DATA ----\n",
    "results = parse_results_file(results_file)\n",
    "results_with_outliers = parse_results_file(results_with_outliers_file, with_outliers=True)\n",
    "\n",
    "# ---- TASK 5 ----\n",
    "rows = []\n",
    "zscore_diffs = []\n",
    "iso_diffs = []\n",
    "zscore_percs = []\n",
    "iso_percs = []\n",
    "\n",
    "for dataset in datasets_task5:\n",
    "    base = results.get(dataset, {})\n",
    "    mlp_acc = base.get(\"mlp\", None)\n",
    "    xgb_acc = base.get(\"xgboost\", None)\n",
    "    diff = (mlp_acc - xgb_acc) if mlp_acc is not None and xgb_acc is not None else None\n",
    "\n",
    "    outlier_info = get_outlier_data(dataset)\n",
    "    zscore = outlier_info.get(\"ZScore\", None)\n",
    "    iso = outlier_info.get(\"IsolationForest\", None)\n",
    "\n",
    "    if diff is not None:\n",
    "        if zscore is not None:\n",
    "            zscore_diffs.append(diff)\n",
    "            zscore_percs.append(zscore)\n",
    "        if iso is not None:\n",
    "            iso_diffs.append(diff)\n",
    "            iso_percs.append(iso)\n",
    "\n",
    "    rows.append({\n",
    "        \"Dataset\": dataset,\n",
    "        \"MLP\": mlp_acc,\n",
    "        \"XGBoost\": xgb_acc,\n",
    "        \"Difference\": diff,\n",
    "        \"ZScore %\": zscore,\n",
    "        \"IsolationForest %\": iso\n",
    "    })\n",
    "\n",
    "# Correlation row\n",
    "z_corr = pearsonr(zscore_diffs, zscore_percs)[0] if len(zscore_diffs) >= 2 else None\n",
    "iso_corr = pearsonr(iso_diffs, iso_percs)[0] if len(iso_diffs) >= 2 else None\n",
    "\n",
    "rows.append({\n",
    "    \"Dataset\": \"Correlation\",\n",
    "    \"MLP\": \"\",\n",
    "    \"XGBoost\": \"\",\n",
    "    \"Difference\": \"\",\n",
    "    \"ZScore %\": z_corr,\n",
    "    \"IsolationForest %\": iso_corr\n",
    "})\n",
    "\n",
    "pd.DataFrame(rows).to_csv(\"task5.csv\", index=False)\n",
    "\n",
    "# ---- TASK 6 ----\n",
    "rows = []\n",
    "for dataset in datasets_task6and7:\n",
    "    base = results.get(dataset, {})\n",
    "    lr = base.get(\"LinearRegression\", None)\n",
    "    mlp = base.get(\"mlp\", None)\n",
    "    xgb = base.get(\"xgboost\", None)\n",
    "    diff_mlp = (mlp - lr) if mlp is not None and lr is not None else None\n",
    "    diff_xgb = (xgb - lr) if xgb is not None and lr is not None else None\n",
    "\n",
    "    outlier_info = get_outlier_data(dataset)\n",
    "    zscore = outlier_info.get(\"ZScore\", None)\n",
    "    iso = outlier_info.get(\"IsolationForest\", None)\n",
    "\n",
    "    rows.append({\n",
    "        \"Dataset\": dataset,\n",
    "        \"LinearRegression\": lr,\n",
    "        \"MLP\": mlp,\n",
    "        \"XGBoost\": xgb,\n",
    "        \"MLP-LR Diff\": diff_mlp,\n",
    "        \"XGB-LR Diff\": diff_xgb,\n",
    "        \"ZScore %\": zscore,\n",
    "        \"IsolationForest %\": iso\n",
    "    })\n",
    "\n",
    "pd.DataFrame(rows).to_csv(\"task6.csv\", index=False)\n",
    "\n",
    "# ---- TASK 7 ----\n",
    "rows = []\n",
    "\n",
    "for dataset in datasets_task6and7:\n",
    "    row = {\"Dataset\": dataset}\n",
    "    base = results.get(dataset, {})\n",
    "    lr = base.get(\"LinearRegression\", None)\n",
    "    row[\"LinearRegression\"] = lr\n",
    "\n",
    "    for technique in techniques:\n",
    "        lr_acc = results_with_outliers.get(dataset, {}).get(\"LinearRegression\", {}).get(technique, None)\n",
    "        row[technique] = lr_acc\n",
    "    rows.append(row)\n",
    "\n",
    "pd.DataFrame(rows).to_csv(\"task7.csv\", index=False)\n",
    "\n",
    "print(\"All CSV files created: task5.csv, task6.csv, task7.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54689c3f-7e55-4fd3-b201-5fa580e85148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "162c0497-5d10-4028-a285-4124e49e160e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e53153e-8350-4e44-a4c3-444113577aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
